



from bs4 import BeautifulSoup
from datetime import datetime

import json
import requests

results = []
#known_cve = []





# saves data to json file with name inputed to get cve
def save_data(data,name):
    with open(f'{name}_exploits.json', 'a+') as file:
        json.dump(data,file, indent  =4)
        file.close()



def do_work(url, name, i):

    res = get_response(url)

    cve_id = str(url).split('cve_id=')[1]
    print(cve_id)
    #print(res.text)
    if 'Unknown CVE ID' not in res.text:
        #known_cve.append(i)
        #print(known_cve)
        url_to_data(res, cve_id, name)
    else:
        print('No CVE')


def get_response(url):

    try:
        res = requests.get(url)
        return res
    except Exception as e:
        print(e)
        pass

#get data from an url
def url_to_data (res, cve_id ,name) :
    try:
        data = dict()
        soup = BeautifulSoup(res.text, 'html.parser')

        td = [str(x.text).replace('\n', ' ').replace('\t', '').strip() for x in soup.findAll('td')]
        data['cve_id'] = cve_id
        data['cve_score'] = str(soup.find('div', {'class': 'cvssbox'}).text).strip()
        data['cve_description'] = str(
            soup.find('div', {
                'class': 'cvedetailssummary'
            }).text) \
            .replace('\n', ' ') \
            .replace('\t', '') \
            .strip()
        all_date = str(
            soup.find('span', {
                'class': 'datenote'
            }).text) \
            .replace('\n', ' ') \
            .replace('\t', '') \
            .strip()
        data['cve_publish_date'] = all_date[15:25]
        data['cve_last_update_date'] = all_date[44:]
        if name in data['cve_description']:
            save_data(data,name)
            print(f'[+] {cve_id} Successfully Saved')
            return True
        else:
            print(f'No {name}')
            return False


    except Exception as e:
        print(e)
        return False


def run(name):



    try:
        for year in range(2021, int(datetime.now().year) + 1):
            prefix = 'https://www.cvedetails.com/cve-details.php?cve_id=CVE-' + str(year) + '-{:04n}'
            #urls = [prefix.format(i) for i in range(0, 50000)]
            #for url in urls:

                #do_work(url.strip(),name)
            for i in range(50000, 60000):
                url = prefix.format(i)
                do_work(url.strip(),name,i)
    except KeyboardInterrupt:



        return False

if __name__ == '__main__':
    #list = ['monkey','donkey']
    #save_data(list,True,'monkey')
    run('')
