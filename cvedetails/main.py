



from bs4 import BeautifulSoup
from datetime import datetime

import json
import requests








# saves data to json file with name inputed to get cve
def save_data(data,name):
    with open(f'{name}_exploits.json', 'a+') as file:
        json.dump(data,file, indent  =4)
        file.close()



def do_work(url, name, i):

    res = get_response(url)

    cve_id = str(url).split('cve_id=')[1]
    print(cve_id)
    #print(res.text)
    if 'Unknown CVE ID' not in res.text:


        cve_new = i

        url_to_data(res, cve_id, name)
        return cve_new
    else:
        return False


def get_response(url):

    try:
        res = requests.get(url)
        return res
    except Exception as e:
        print(e)
        pass

#get data from an url
def url_to_data (res, cve_id ,name) :
    try:
        data = dict()
        soup = BeautifulSoup(res.text, 'html.parser')

        td = [str(x.text).replace('\n', ' ').replace('\t', '').strip() for x in soup.findAll('td')]
        data['cve_id'] = cve_id
        data['cve_score'] = str(soup.find('div', {'class': 'cvssbox'}).text).strip()
        data['cve_description'] = str(
            soup.find('div', {
                'class': 'cvedetailssummary'
            }).text) \
            .replace('\n', ' ') \
            .replace('\t', '') \
            .strip()
        all_date = str(
            soup.find('span', {
                'class': 'datenote'
            }).text) \
            .replace('\n', ' ') \
            .replace('\t', '') \
            .strip()
        data['cve_publish_date'] = all_date[15:25]
        data['cve_last_update_date'] = all_date[44:]
        if name in data['cve_description']:
            save_data(data,name)
            print(f'[+] {cve_id} Successfully Saved')
            return True
        else:
            print(f'No {name}')
            return False


    except Exception as e:
        print(e)
        return False


def run(name):

    with open('update_exploits.txt', 'r') as fileupdate:
        update_data = fileupdate.readline()


        try:
            for year in range(2021, int(datetime.now().year) + 1):
                prefix = 'https://www.cvedetails.com/cve-details.php?cve_id=CVE-' + str(year) + '-{:04n}'
                #urls = [prefix.format(i) for i in range(0, 50000)]
                #for url in urls:

                    #do_work(url.strip(),name)
                for i in range(int(update_data), int(update_data)+216):
                    url = prefix.format(i)
                    new_start = do_work(url.strip(),name,i)
                    if new_start == False:
                        no_new = new_start
                    else:
                        new_cve = new_start


        except KeyboardInterrupt:



            return False

    if new_cve == update_data:
        return print('No new cve')
    else:
        print('new_cve = ', new_cve)
        with open('update_exploits.txt', 'w') as fileupdate:
            fileupdate.write(str(new_cve))

if __name__ == '__main__':
    
    run('')
